{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone 2 - R20MTA07- Smart parking solution for multi building campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# People counter tracker\n",
    "\n",
    "import math\n",
    "\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Store the center positions of the objects\n",
    "        self.center_points = {}\n",
    "        # Keep the count of the IDs\n",
    "        # each time a new object id detected, the count will increase by one\n",
    "        self.id_count = 0\n",
    "\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        # Objects boxes and ids\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Get center point of new object\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h, index = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Find out if that object was detected already\n",
    "            same_object_detected = False\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "\n",
    "                if dist < 25:\n",
    "                    self.center_points[id] = (cx, cy)\n",
    "                    # print(self.center_points)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id, index])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # New object is detected we assign the ID to that object\n",
    "            if same_object_detected is False:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count, index])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Clean the dictionary by center points to remove IDS not used anymore\n",
    "        new_center_points = {}\n",
    "        for obj_bb_id in objects_bbs_ids:\n",
    "            _, _, _, _, object_id, index = obj_bb_id\n",
    "            center = self.center_points[object_id]\n",
    "            new_center_points[object_id] = center\n",
    "\n",
    "        # Update dictionary with IDs not used removed\n",
    "        self.center_points = new_center_points.copy()\n",
    "        return objects_bbs_ids\n",
    "\n",
    "def ad(a, b):\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# Vehicle movement counting and Classification\n",
    "\n",
    "# Import necessary packages\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Tracker\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Detection confidence threshold\n",
    "confThreshold =0.5\n",
    "nmsThreshold= 0.4\n",
    "\n",
    "font_color = (0, 0, 255)\n",
    "font_size = 0.5\n",
    "font_thickness = 2\n",
    "\n",
    "# Middle cross line position\n",
    "middle_line_position = 260   \n",
    "exit_line_position = middle_line_position - 15\n",
    "entry_line_position = middle_line_position + 15\n",
    "\n",
    "\n",
    "# Store Coco Names in a list\n",
    "classesFile = \"coco.names\"\n",
    "classNames = open(classesFile).read().strip().split('\\n')\n",
    "print(classNames)\n",
    "print(len(classNames))\n",
    "\n",
    "# class index for our required detection classes. \n",
    "required_class_index = [2]  # Car\n",
    "\n",
    "detected_classNames = []\n",
    "\n",
    "# configure the network model\n",
    "#net = cv2.dnn.readNet(modelWeigheights, modelConfiguration)\n",
    "net = cv2.dnn.readNet(\"yolov4.weights\", \"yolov4.cfg\")\n",
    "\n",
    "# Configure the network backend\n",
    "\n",
    "#net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "#net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\n",
    "\n",
    "# Define random colour for each class\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classNames), 3), dtype='uint8')\n",
    "\n",
    "\n",
    "# Function for finding the center of a rectangle\n",
    "def find_center(x, y, w, h):\n",
    "    x1=int(w/2)\n",
    "    y1=int(h/2)\n",
    "    cx = x+x1\n",
    "    cy=y+y1\n",
    "    return cx, cy\n",
    "    \n",
    "# List for store vehicle count information\n",
    "temp_exit_list = []\n",
    "temp_entry_list = []\n",
    "exit_list = [0, 0, 0, 0]\n",
    "entry_list = [0, 0, 0, 0]\n",
    "\n",
    "# Function for count vehicle\n",
    "def count_vehicle(box_id, img):\n",
    "\n",
    "    x, y, w, h, id, index = box_id\n",
    "\n",
    "    # Find the center of the rectangle for detection\n",
    "    center = find_center(x, y, w, h)\n",
    "    ix, iy = center\n",
    "    \n",
    "    # Find the current position of the vehicle\n",
    "    if (iy > exit_line_position) and (iy < middle_line_position):\n",
    "\n",
    "        if id not in temp_exit_list:\n",
    "            temp_exit_list.append(id)\n",
    "\n",
    "    elif iy < entry_line_position and iy > middle_line_position:\n",
    "        if id not in temp_entry_list:\n",
    "            temp_entry_list.append(id)\n",
    "            \n",
    "    elif iy < exit_line_position:\n",
    "        if id in temp_entry_list:\n",
    "            temp_entry_list.remove(id)\n",
    "            exit_list[index] = exit_list[index]+1\n",
    "\n",
    "    elif iy > entry_line_position:\n",
    "        if id in temp_exit_list:\n",
    "            temp_exit_list.remove(id)\n",
    "            entry_list[index] = entry_list[index] + 1\n",
    "\n",
    "    # Draw circle in the middle of the rectangle\n",
    "    cv2.circle(img, center, 2, (0, 0, 255), -1)  # end here\n",
    "    # print(exit_list, entry_list)\n",
    "\n",
    "# Function for finding the detected objects from the network output\n",
    "def postProcess(outputs,img):\n",
    "    global detected_classNames \n",
    "    height, width = img.shape[:2]\n",
    "    boxes = []\n",
    "    classIds = []\n",
    "    confidence_scores = []\n",
    "    detection = []\n",
    "    for output in outputs:\n",
    "        for det in output:\n",
    "            scores = det[5:]\n",
    "            classId = np.argmax(scores)\n",
    "            confidence = scores[classId]\n",
    "            if classId in required_class_index:\n",
    "                if confidence > confThreshold:\n",
    "                    # print(classId)\n",
    "                    w,h = int(det[2]*width) , int(det[3]*height)\n",
    "                    x,y = int((det[0]*width)-w/2) , int((det[1]*height)-h/2)\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    classIds.append(classId)\n",
    "                    confidence_scores.append(float(confidence))\n",
    "\n",
    "    # Apply Non-Max Suppression\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidence_scores, confThreshold, nmsThreshold)\n",
    "    # print(classIds)\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            # print(x,y,w,h)\n",
    "\n",
    "            color = [int(c) for c in colors[classIds[i]]]\n",
    "            name = classNames[classIds[i]]\n",
    "            detected_classNames.append(name)\n",
    "            # Draw classname and confidence score \n",
    "            cv2.putText(img,f'{name.upper()} {int(confidence_scores[i]*100)}%',\n",
    "                      (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "            # Draw bounding rectangle\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 1)\n",
    "            detection.append([x, y, w, h, required_class_index.index(classIds[i])])\n",
    "\n",
    "        # Udate the tracker for each object\n",
    "        boxes_ids = tracker.update(detection)\n",
    "        for box_id in boxes_ids:\n",
    "            count_vehicle(box_id, img)\n",
    "\n",
    "input_size = 512\n",
    "\n",
    "# Initialize the videocapture object\n",
    "cap = cv2.VideoCapture('medium-long-48.mp4')\n",
    "\n",
    "def realTime():\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        img = cv2.resize(img,(0,0),None,0.5,0.5)\n",
    "        ih, iw, channels = img.shape\n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255, (input_size, input_size), [0, 0, 0], 1, crop=False)\n",
    "\n",
    "        # Set the input of the network\n",
    "        net.setInput(blob)\n",
    "        layersNames = net.getLayerNames()\n",
    "        outputNames = [(layersNames[i[0] - 1]) for i in net.getUnconnectedOutLayers()]\n",
    "        # Feed data to the network\n",
    "        outputs = net.forward(outputNames)\n",
    "    \n",
    "        # Find the objects from the network output\n",
    "        postProcess(outputs,img)\n",
    "\n",
    "        # Draw the crossing lines\n",
    "\n",
    "        cv2.line(img, (0, middle_line_position), (iw, middle_line_position), (255, 0, 255), 2)\n",
    "        cv2.line(img, (0, exit_line_position), (iw, exit_line_position), (0, 0, 255), 2)\n",
    "        cv2.line(img, (0, entry_line_position), (iw, entry_line_position), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw counting texts in the frame\n",
    "        cv2.putText(img, \"Entry\", (110, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Exit\", (160, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Available\", (210, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Total\", (300, 20), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        cv2.putText(img, \"Car:        \"+str(entry_list[0])+\"     \"+ str(exit_list[0])+\"       \"+ str(48- (entry_list[0]-exit_list[0]))+\"         \"+ str(48), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, font_size, font_color, font_thickness)\n",
    "        \n",
    "        # Show the frames\n",
    "        cv2.imshow('Output', img)\n",
    "\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Write the vehicle counting information in a file and save it\n",
    "\n",
    "    with open(\"data.csv\", 'w') as f1:\n",
    "        cwriter = csv.writer(f1)\n",
    "        cwriter.writerow(['Direction', 'car'])\n",
    "        exit_list.insert(0, \"exit\")\n",
    "        entry_list.insert(0, \"entry\")\n",
    "        cwriter.writerow(exit_list)\n",
    "        cwriter.writerow(entry_list)\n",
    "    f1.close()\n",
    "    # print(\"Data saved at 'data.csv'\")\n",
    "    # Finally realese the capture object and destroy all active windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    realTime()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.5\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
